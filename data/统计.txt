思路修正：
1.如何突破上下翻页链接最多100页的限制？
答：遍历所有小区，分别获取每个小区的租房列表
2.如何获取所有小区
答：根据区域，抓取所有区域的小区列表
http://bj.lianjia.com/xiaoqu/dongcheng/
建立小区信息表：id, lj_no, areaid(区域表ID，二级区域), lineid(地铁线路表ID，站点)
3.运行思路
小区租房列表，例如青年湖东里：http://bj.lianjia.com/zufang/c1111027378889/
程序每天抓取所有小区的租房信息一次，写入/更新到租房信息表，设置当前记录的更新时间为当天，并设置“是否成交”字段为“否”。
抓取完毕后，遍历租房信息表，将更新时间不等于当天的记录的“是否成交”字段置为“是”。
4.统计思路
每日写入day统计表
每周日写入week统计表
每月1号写入month统计表


反爬策略：
-降低抓取频率，时间设置长一些，访问时间采用随机数
-频繁切换UserAgent（模拟浏览器访问）
-多页面数据，随机访问然后抓取数据
-更换用户IP
-网站提供API，减少风险
-多线程



统计项目：
1.各区域租房数量分布
2.户型分布
3.面积分布
4.朝向分布
5.楼层分布
6.地铁沿线租房数量分布top10
7.地铁站点租房数量分布top10
8.小区租房数量分布top10
9.小区均价排行top10
10.建筑年代分布
11.每天新增/减少的房源数量
12.以北京市地图的方式展示，点击某个区域可以查看当前区域的相关数据
13.每日新增房源数（跑脚本前先查询前一天在租的房源数，跑完设置完is_rent后计算当天房源数，相减）、昨日更新房源数（build_info的update_time为当天的）

跑完每日的脚本后，查询build_info表最后修改时间不是当天的，is_rent全部修改为1

后续功能：
个人关注/收藏小区（详情、房源数、价格排行）
个人关注/收藏房源（详情、价格走势）


t_build:
id、build_no、areaPid、areaid、districtid、url、cover、title、zone、meters、direction、floor、build_year、build_type、lineid、siteid、price、decoration、balcony、bathroom、heating、visit、is_rent、update_time

t_stat_201611_day:
id、buildid、20161121、20161122...

t_stat_201611_week:
id、buildid、w1_start、w1_end、w1_low、w1_high、w1_ave、w2_start、w2_end、w2_low、w2_high、w2_ave、w3_start、w3_end、w3_low、w3_high、w3_ave、w4_start、w4_end、w4_low、w4_high、w4_ave

t_stat_201611_month:
id、buildid、low、high、average、rate